{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DataStax Academy](https://s3.amazonaws.com/datastaxtraining/vq8Jr36Gk48v/datastax-academy.svg \"DataStax Academy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 19 - Tuning Partitioning: Partitioning Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you'll be exploring partitioning properties for RDDs created from different sources and transformations.\n",
    "\n",
    "You'll be working with the `videos` table:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CREATE TABLE killr_video.videos (\n",
    "    video_id TIMEUUID,\n",
    "    avg_rating FLOAT,\n",
    "    description TEXT,\n",
    "    genres SET<TEXT>,\n",
    "    mpaa_rating TEXT,\n",
    "    release_date TIMESTAMP,\n",
    "    release_year INT,\n",
    "    title TEXT,\n",
    "    user_id UUID,\n",
    "    PRIMARY KEY (video_id)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and a text file, `/root/data/video-ids.csv`, which contains only one column: the video IDs for different movies. Some of the video IDs are orphaned, i.e. not in the `killrvideo.videos` table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create an RDD from the text file. Hint: map() each row to a UUID via java.util.UUID.fromString(). What do you expect the partitioner and number of partitions to be? Why? Write Scala code to discover the actual values. Were they what you expected them to be? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "val rdd1 = sc.textFile(\"file:///root/data/video-ids.csv\")\n",
    "    .map(row => java.util.UUID.fromString(row))\n",
    "println(rdd1.partitioner)\n",
    "println(rdd1.partitions.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Create an RDD from the killrvideo.videos table select()ing only the videoids. What do you expect the partitioner and number of partitions to be? Why? Write Scala code to discover the actual values. Were they what you expected them to be? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "val rdd2 = sc.cassandraTable[java.util.UUID](\"killr_video\", \"videos\")\n",
    "    .select(\"video_id\")\n",
    "println(rdd2.partitioner)\n",
    "println(rdd2.partitions.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Find the orphaned video IDs by using subtract(). What do you expect the partitioner and number of partitions to be? Why? Write Scala code to discover the actual values. Were they what you expected them to be? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "val rdd3 = rdd1.subtract(rdd2)\n",
    "\n",
    "println(rdd3.partitioner)\n",
    "println(rdd3.partitions.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Turn your RDD into a RDD of keys via keyBy() then sort using sortByKey(). What do you expect the partitioner and number of partitions to be? Why? Write Scala code to discover the actual values. Were they what you expected them to be? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some(org.apache.spark.RangePartitioner@daac8b75)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "val rdd4 = rdd3.keyBy(row => row).sortByKey()\n",
    "\n",
    "println(rdd4.partitioner)\n",
    "println(rdd4.partitions.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Display the resulting orphaned video IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9056808b-ca65-1bfb-9957-3bea148dfdce,9056808b-ca65-1bfb-9957-3bea148dfdce)\n",
      "(907df86e-2208-18a8-90aa-6d837c659f2f,907df86e-2208-18a8-90aa-6d837c659f2f)\n",
      "(9646278f-14bd-11e5-88ea-8438355b7e3a,9646278f-14bd-11e5-88ea-8438355b7e3a)\n",
      "(9db57288-e51c-1ff1-805d-c5f1e49c2c8b,9db57288-e51c-1ff1-805d-c5f1e49c2c8b)\n",
      "(fe3c4045-6f37-1223-81be-250dc60cffc8,fe3c4045-6f37-1223-81be-250dc60cffc8)\n",
      "(2645e79c-14bd-11e5-a456-8438355b7e3a,2645e79c-14bd-11e5-a456-8438355b7e3a)\n",
      "(264601a3-14bd-11e5-8c2e-8438355b7e3a,264601a3-14bd-11e5-8c2e-8438355b7e3a)\n",
      "(2646123a-14bd-11e5-b9db-8438355b7e3a,2646123a-14bd-11e5-b9db-8438355b7e3a)\n",
      "(26461a70-14bd-11e5-ad08-8438355b7e3a,26461a70-14bd-11e5-ad08-8438355b7e3a)\n",
      "(2e8ecb4f-e92b-139b-8183-4df0e2a817bb,2e8ecb4f-e92b-139b-8183-4df0e2a817bb)\n"
     ]
    }
   ],
   "source": [
    "rdd4.collect.foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark-DSE Cluster",
   "language": "scala",
   "name": "spark-dse-cluster"
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
