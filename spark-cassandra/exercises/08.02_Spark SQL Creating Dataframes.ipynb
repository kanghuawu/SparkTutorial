{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DataStax Academy](https://s3.amazonaws.com/datastaxtraining/vq8Jr36Gk48v/datastax-academy.svg \"DataStax Academy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 08.02 - Spark SQL: Creating Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be reviewing several ways to create a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by creating an dataframe using the `toDF` method and inferring the schema using reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|               title|year|\n",
      "+--------------------+----+\n",
      "|Pirates of the Ca...|2011|\n",
      "+--------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sqlContext.implicits._\n",
    "\n",
    "case class Movie(title: String, year: Int)\n",
    "\n",
    "val rdd = sc.parallelize(Array(Movie(\"Pirates of the Caribbean Sea\", 2011)))\n",
    "\n",
    "val df = rdd.toDF()\n",
    "\n",
    "df.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a dataframe specifying the schema programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|               title|year|\n",
      "+--------------------+----+\n",
      "|Pirates of the Ca...|2011|\n",
      "+--------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.Row\n",
    "import org.apache.spark.sql.types._\n",
    "\n",
    "val rdd = sc.parallelize(Array((\"Pirates of the Caribbean Sea\", 2011)))\n",
    "    .map{case(t, y) => Row(t, y)}\n",
    "\n",
    "val schema = StructType(List(\n",
    "    StructField(\"title\", StringType, false),\n",
    "    StructField(\"year\", IntegerType, false)))\n",
    "\n",
    "val df = sqlContext.createDataFrame(rdd, schema)\n",
    "\n",
    "df.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe specifying a SQL query. The types will be inferred from the table and this is an optimal method to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------------------+--------------------+-----------+--------------------+------------+--------------------+-----------+\n",
      "|   video_id|avg_rating|         description|              genres|mpaa_rating|        release_date|release_year|               title|    user_id|\n",
      "+-----------+----------+--------------------+--------------------+-----------+--------------------+------------+--------------------+-----------+\n",
      "|[B@2ca8f3f3|       7.0|After being wrong...|  ArrayBuffer(Crime)|          R|2005-09-09 00:00:...|        2005|Green Street Hool...|[B@54b225c3|\n",
      "|[B@16d1120c|       5.8|Paulie, an intell...| ArrayBuffer(Family)|         PG|1998-04-17 00:00:...|        1998|              Paulie|[B@61b3d4cc|\n",
      "| [B@aef9462|       6.0|A Reno singer wit...| ArrayBuffer(Comedy)|         PG|1992-05-28 00:00:...|        1992|          Sister Act|[B@4fb624c1|\n",
      "|[B@51e91e49|       6.1|After a lightning...|ArrayBuffer(Famil...|         PG|1986-05-09 00:00:...|        1986|       Short Circuit|[B@2e83b50c|\n",
      "|[B@5839783a|       5.4|A medieval tale w...| ArrayBuffer(Comedy)|         PG|1977-03-28 00:00:...|        1977|         Jabberwocky|[B@2657dfd0|\n",
      "|[B@3f559605|       5.6|A parolee battles...|  ArrayBuffer(Crime)|          R|2010-11-10 00:00:...|        2010|    London Boulevard| [B@c4d6f36|\n",
      "|[B@1fa63e2d|       6.1|A Shakespearean a...| ArrayBuffer(Horror)|          R|1973-04-05 00:00:...|        1973|    Theatre of Blood| [B@797cb56|\n",
      "|[B@14e1801f|       6.3|Dorothy, saved fr...|ArrayBuffer(Famil...|         PG|1985-06-21 00:00:...|        1985|        Return to Oz|[B@73b2696a|\n",
      "|[B@5dcb6667|       6.0|Ninja Assassin fo...|ArrayBuffer(Crime...|          R|2009-09-29 00:00:...|        2009|      Ninja Assassin|[B@643fdbf3|\n",
      "|[B@7cc64e13|       5.6|Al Stump is a fam...|       ArrayBuffer()|          R|1994-12-02 00:00:...|        1994|                Cobb|[B@1cdf81d8|\n",
      "+-----------+----------+--------------------+--------------------+-----------+--------------------+------------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val df = sqlContext.sql(\"SELECT * FROM killr_video.videos\")\n",
    "df.limit(10).show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's create a dataframe using the dataframe reader method. `sqlContext.read`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+--------------------+-----------+--------------------+------------+--------------------+--------------------+\n",
      "|            video_id|avg_rating|         description|              genres|mpaa_rating|        release_date|release_year|               title|             user_id|\n",
      "+--------------------+----------+--------------------+--------------------+-----------+--------------------+------------+--------------------+--------------------+\n",
      "|ece8de8f-a5e2-11e...|       7.0|After being wrong...|  ArrayBuffer(Crime)|          R|2005-09-09 00:00:...|        2005|Green Street Hool...|6b234a61-faa6-4b4...|\n",
      "|ecf288d1-a5e2-11e...|       5.8|Paulie, an intell...| ArrayBuffer(Family)|         PG|1998-04-17 00:00:...|        1998|              Paulie|6b234a61-faa6-4b4...|\n",
      "|ece73c02-a5e2-11e...|       6.0|A Reno singer wit...| ArrayBuffer(Comedy)|         PG|1992-05-28 00:00:...|        1992|          Sister Act|6b234a61-faa6-4b4...|\n",
      "|ece77fe6-a5e2-11e...|       6.1|After a lightning...|ArrayBuffer(Famil...|         PG|1986-05-09 00:00:...|        1986|       Short Circuit|6b234a61-faa6-4b4...|\n",
      "|eceb8257-a5e2-11e...|       5.4|A medieval tale w...| ArrayBuffer(Comedy)|         PG|1977-03-28 00:00:...|        1977|         Jabberwocky|6b234a61-faa6-4b4...|\n",
      "|ecf5adbd-a5e2-11e...|       5.6|A parolee battles...|  ArrayBuffer(Crime)|          R|2010-11-10 00:00:...|        2010|    London Boulevard|6b234a61-faa6-4b4...|\n",
      "|ecf1210f-a5e2-11e...|       6.1|A Shakespearean a...| ArrayBuffer(Horror)|          R|1973-04-05 00:00:...|        1973|    Theatre of Blood|6b234a61-faa6-4b4...|\n",
      "|ecec23e8-a5e2-11e...|       6.3|Dorothy, saved fr...|ArrayBuffer(Famil...|         PG|1985-06-21 00:00:...|        1985|        Return to Oz|6b234a61-faa6-4b4...|\n",
      "|ecefae51-a5e2-11e...|       6.0|Ninja Assassin fo...|ArrayBuffer(Crime...|          R|2009-09-29 00:00:...|        2009|      Ninja Assassin|6b234a61-faa6-4b4...|\n",
      "|ecf1689e-a5e2-11e...|       5.6|Al Stump is a fam...|                null|          R|1994-12-02 00:00:...|        1994|                Cobb|6b234a61-faa6-4b4...|\n",
      "+--------------------+----------+--------------------+--------------------+-----------+--------------------+------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val df = sqlContext.read\n",
    "    .format(\"org.apache.spark.sql.cassandra\")\n",
    "    .options(Map(\"keyspace\" -> \"killr_video\", \"table\" -> \"videos\"))\n",
    "    .load\n",
    "    .limit(10)\n",
    "\n",
    "df.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark-DSE Cluster",
   "language": "scala",
   "name": "spark-dse-cluster"
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
