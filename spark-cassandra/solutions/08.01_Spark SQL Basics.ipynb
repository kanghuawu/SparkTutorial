{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DataStax Academy](https://s3.amazonaws.com/datastaxtraining/vq8Jr36Gk48v/datastax-academy.svg \"DataStax Academy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 08.01 - Spark SQL: SQL Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we will be executing a few simple SQL queries."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CREATE TABLE videos_by_actor (\n",
    "  actor_name TEXT,\n",
    "  release_year INT,\n",
    "  character_name TEXT,\n",
    "  video_id TIMEUUID,\n",
    "  title TEXT,\n",
    "  PRIMARY KEY (actor_name, release_year)\n",
    ") ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark SQL is a relational engine on top of spark! Typically you will have the CassandraSQLContext, HiveContext and SQLContext at your disposal, but for the purposes of interacting with the Spark Kernel, we will be using the `sqlContext` which is based on the `HiveContext` discussed in the tutorial video. Don't worry the functionality should be the same!\n",
    "\n",
    "To test that your context is executing against the cluster, let's begin by executing it standalone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.hive.HiveContext = org.apache.spark.sql.hive.HiveContext@1a1f22f2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We will be able to execute SQL statements with this context. Let's begin with a Select count from `videos_by_actor` where the actor is `Johnny Depp`. This is returning a dataframe, that is why we are including the `.show`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|total|\n",
      "+-----+\n",
      "|   26|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"SELECT COUNT(*) AS total FROM killr_video.videos_by_actor WHERE actor_name = 'Johnny Depp'\").show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Language-Integrated Queries use the API of the Spark context. Using the `read` method is similar to the `select` mentioned above. The `filter` acts like `where` clause in standard SQL. Let's recreate the same query above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val movies = sqlContext.read.format(\"org.apache.spark.sql.cassandra\").options(Map(\"keyspace\" -> \"killr_video\", \"table\" -> \"videos_by_actor\")).load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|total|\n",
      "+-----+\n",
      "|   26|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies.filter(\"actor_name = 'Johnny Depp' \").agg(Map(\"*\" -> \"count\")).withColumnRenamed(\"COUNT(1)\", \"total\").show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark-DSE Cluster",
   "language": "scala",
   "name": "spark-dse-cluster"
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
