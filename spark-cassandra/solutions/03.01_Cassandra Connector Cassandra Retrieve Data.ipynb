{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DataStax Academy](https://s3.amazonaws.com/datastaxtraining/vq8Jr36Gk48v/datastax-academy.svg \"DataStax Academy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 03.01 - Cassandra Connector: Cassandra Retrieve Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise will have you practice using the Spark Cassandra API, which you'll be using to implement a CQL query to retrieve data in Spark.\n",
    "\n",
    "The data comes from a Cassandra table, `videos_by_year_title`, with the following definition:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CREATE TABLE killr_video.videos_by_year_title (\n",
    "    added_year INT,\n",
    "    title TEXT,\n",
    "    video_id TIMEUUID,\n",
    "    added_date TIMESTAMP,\n",
    "    avg_rating FLOAT,\n",
    "    description TEXT,\n",
    "    user_id UUID,\n",
    "    PRIMARY KEY (added_year, title, video_id)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Write a Spark query to retrieve movies in the year 2015 where the movie title starts with the letter `T` or greater. Print the results taking only the first five records. Be sure to use the Spark Cassandra API rather than the Spark functions themselves so that Cassandra does as much of the processing as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taken 3\n",
      "Tales of Halloween\n",
      "Tangerine\n",
      "Ted 2\n",
      "Terminator Genisys\n"
     ]
    }
   ],
   "source": [
    "val qryPart1 = sc.cassandraTable(\"killr_video\", \"videos_by_year_title\").select(\"title\")\n",
    "val qryPart2 = qryPart1.where(\"added_year = 2015 and title >= 'T'\").limit(5)\n",
    "val resultRDD = qryPart2.collect\n",
    "resultRDD.foreach(row => println(row.getString(\"title\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Rewrite your query to use Spark API instead of the Spark Cassandra API functions. Remember that this way is less optimal because it causes Spark to load and process all the data from Cassandra itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taken 3\n",
      "Tales of Halloween\n",
      "Tangerine\n",
      "Ted 2\n",
      "Terminator Genisys\n"
     ]
    }
   ],
   "source": [
    "val rows = sc.cassandraTable(\"killr_video\", \"videos_by_year_title\")\n",
    "val filterYear = rows.filter(record => record.getInt(\"added_year\") == 2015)\n",
    "val filterTitle = filterYear.map(record => record.getString(\"title\")).filter(title => title >= \"T\")\n",
    "filterTitle.take(5).foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice with the Cassandra API, order of function calls doesn’t matter as the calls are metadata for a Cassandra query. However in the Spark API, order matters. We can’t `take()` before we `filter()` or else `filter()` will only evaluate the number of records we `take()`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark-DSE Cluster",
   "language": "scala",
   "name": "spark-dse-cluster"
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
